{
<<<<<<< HEAD
<<<<<<< HEAD
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
    "## GAN Data-Debiasing\n",
=======
    "## NNabla-GAN-Debiasing\n",
>>>>>>> 80cfa23 (added tutorial notebook for gan debiasing - Part2)
=======
    "## GAN Data-Debiasing\n",
>>>>>>> 29eb436 (renamed the image name & tutorial title)
=======
    "## NNabla-GAN-Debiasing\n",
>>>>>>> 80cfa23 (added tutorial notebook for gan debiasing - Part2)
=======
    "## GAN Data-Debiasing\n",
>>>>>>> 29eb436 (renamed the image name & tutorial title)
=======
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PBtwxoAiHWnh"
   },
   "source": [
    "## GAN Data-Debiasing\n",
>>>>>>> 718c992 (1. added pre-trained weight links in notebook)
    "\n",
    "### Table of contents :\n",
    "1. [Introduction](#1.-Introduction)\n",
    "2. [Train Attribute Classifier](#2.-Train-Attribute-Classifier)\n",
    "\t* [Compute Fairness](#Compute-fairness-of-Attribute-classifier)\n",
    "3. [Mitigate bias using GAN's Latent Space De-biasing.](#3.-Mitigate-the-bias-using-GAN's-Latent-Space-De-biasing)\n",
    "4. [Train Attribute classifier with debiased dataset](#4.-Train-Attribute-classifier-with-debiased-dataset)\n",
    "\t* [Compute Fairness](#Compute-Fairness)\n",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
    "5. [Summary](#5.-Summary)"
=======
    "5. [Summary](#5.-Summary)\n"
>>>>>>> 80cfa23 (added tutorial notebook for gan debiasing - Part2)
=======
    "5. [Summary](#5.-Summary)"
>>>>>>> 29eb436 (renamed the image name & tutorial title)
=======
    "5. [Summary](#5.-Summary)\n"
>>>>>>> 80cfa23 (added tutorial notebook for gan debiasing - Part2)
=======
    "5. [Summary](#5.-Summary)"
>>>>>>> 29eb436 (renamed the image name & tutorial title)
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introduction\n",
    "\n",
    "\n",
    "Welcome !\n",
    "\n",
    "\n",
    "Application of Deep Learning for vision problems has proliferated in recent times. Its widespread application necessitates need for \"Fairness\". Deep Learning models trained with only labels as beacons possibly learn spurious correlations between labels and certain features [or attributes].\n",
    "\n",
    "\n",
    "for ex., if we train a model to classify \"people wearing hats\", the classifier may inadvertantly associate sunglasses with hats if the dataset has narrow distribution of mostly outdoor images (people often wear both hats and sunglasses together outdoors and take them off indoors). Because of this correlation in the training data classifier trained to recognize a hat may rely on the presence of glasses. As a result, the classifier may fail to recognize a hat in the absence of sunglasses. Capturing perfectly balanced dataset is not feasible in many cases. In such cases, as shown in this notebook, one could train classifiers while mitigating biases that stem from these correlations, by using [Fair Attribute Classification through Latent Space De-biasing](https://arxiv.org/abs/2012.01469).\n",
    "\n",
    "\n",
    "Before we go into detailed explanation, here is a sneak peek into the steps involved in the process:\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 1,
>>>>>>> 80cfa23 (added tutorial notebook for gan debiasing - Part2)
=======
   "execution_count": null,
>>>>>>> f133105 (added support for download and split the celebA dataset)
=======
   "execution_count": 1,
>>>>>>> 80cfa23 (added tutorial notebook for gan debiasing - Part2)
=======
   "execution_count": null,
>>>>>>> f133105 (added support for download and split the celebA dataset)
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation\n",
    "!git clone https://github.com/sony/nnabla-examples.git\n",
    "%cd nnabla-examples/responsible_ai/gan_data_debiased\n",
    "!pip install albumentations\n",
    "\n",
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
    "img = cv2.imread('images/gan_data_debiasing_workflow.png')\n",
=======
    "img = cv2.imread('images/nnabla_gan_debiasing_workflow.png')\n",
>>>>>>> 80cfa23 (added tutorial notebook for gan debiasing - Part2)
=======
    "img = cv2.imread('images/gan_data_debiasing_workflow.png')\n",
>>>>>>> 29eb436 (renamed the image name & tutorial title)
=======
    "img = cv2.imread('images/nnabla_gan_debiasing_workflow.png')\n",
>>>>>>> 80cfa23 (added tutorial notebook for gan debiasing - Part2)
=======
    "img = cv2.imread('images/gan_data_debiasing_workflow.png')\n",
>>>>>>> 29eb436 (renamed the image name & tutorial title)
    "cv2_imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As illustrated in the picture, we use [GAN](https://arxiv.org/abs/1406.2661) technique to generate realistic-looking images and perturb these images in the underlying latent space to generate training data that is balanced for each protected attribute. Then we augment the original dataset with this generated data and empirically demonstrate that target classifiers trained on the augmented dataset exhibits a number of both quantitative and qualitative benefits.\n",
    "\n",
    "\n",
    "Let's first train a baseline attribute classifier with original [celebA](https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) dataset, analyze model fairness. Then we shall train the target attribute classifier with a balanced dataset and original dataset to make the model fair if fairness metric is not satisfactory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparation"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
=======
>>>>>>> 80cfa23 (added tutorial notebook for gan debiasing - Part2)
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 13:21:57,768 [nnabla][INFO]: Initializing CPU extension...\n"
     ]
    }
   ],
<<<<<<< HEAD
>>>>>>> 80cfa23 (added tutorial notebook for gan debiasing - Part2)
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> f133105 (added support for download and split the celebA dataset)
=======
>>>>>>> 80cfa23 (added tutorial notebook for gan debiasing - Part2)
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> f133105 (added support for download and split the celebA dataset)
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
    "import shutil\n",
=======
>>>>>>> 80cfa23 (added tutorial notebook for gan debiasing - Part2)
=======
    "import shutil\n",
>>>>>>> f133105 (added support for download and split the celebA dataset)
=======
>>>>>>> 80cfa23 (added tutorial notebook for gan debiasing - Part2)
=======
    "import shutil\n",
>>>>>>> f133105 (added support for download and split the celebA dataset)
    "import numpy as np\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "import nnabla as nn\n",
    "from nnabla.ext_utils import get_extension_context\n",
    "from nnabla.utils.data_iterator import data_iterator_simple\n",
    "import classifier as clf\n",
    "from utils import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us train an `Arched Eyebrow` classifier that is not dependent on gender expression. For this, we require a dataset that has target labels (`Arched eyebrow`) as well as gender expression labels. [celebA](https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) is a dataset with 2,022,599 images of celebrity faces, each with 40 binary attributes labels. We assume the `Male` attribute corresponds to gender expression and the target attribute is `Arched Eyebrow`.\n",
    "\n",
    "\n",
    "NNabla provides various utilities for using data for training/validation. Here, we will use NNabla data_iterator_simple.\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 3,
>>>>>>> 80cfa23 (added tutorial notebook for gan debiasing - Part2)
=======
   "execution_count": null,
>>>>>>> f133105 (added support for download and split the celebA dataset)
=======
   "execution_count": 3,
>>>>>>> 80cfa23 (added tutorial notebook for gan debiasing - Part2)
=======
   "execution_count": null,
>>>>>>> f133105 (added support for download and split the celebA dataset)
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_iterator_celeba(img_path,attr_path, batch_size,\n",
    "                         target_attribute=1,protected_attribute=20,\n",
    "                         num_samples=-1,augment=False, shuffle=False, rng=None):\n",
    "    \"\"\"\n",
    "    create celebA data iterator\n",
    "    Args:\n",
    "        img_path (str) : image path directory \n",
    "        attr_path (str) : celebA attribute file path (ex: list_attr_celeba.txt)\n",
    "        batch_size (int) :  number of samples contained in each generated batch\n",
    "        target_attribute (int) : target attribute (ex: Arched EyeBrows (1), Bushy Eyebrows(12), smilling (31),etc..)\n",
    "        protected_attribute (int): protected attribute (ex: Male (20), Pale_Skin (26))\n",
    "        num_samples (int) : number of samples taken in data loader\n",
    "                            (if num_samples=-1, it will take all the images in the dataset)\n",
    "        augment (bool) : data augmentation (True for training)\n",
    "        shuffle (bool) : shuffle the data (True /False)\n",
    "        rng : None\n",
    "    Returns:\n",
    "        simple data iterator\n",
    "    \"\"\"\n",
    "    \n",
    "    imgs = glob.glob(\"{}/*.jpg\".format(img_path))\n",
    "    label_file = open(attr_path, 'r')\n",
    "    label_file = label_file.readlines()\n",
    "    labels = {}\n",
    "    # skipping first two rows(headers)\n",
    "    for i in range(2, len(label_file)):\n",
    "        temp = label_file[i].strip().split()\n",
    "        labels[os.path.join(img_path, temp[0])] = np.array(\n",
    "            [int((int(temp[target_attribute + 1]) + 1) / 2), int((int(temp[protected_attribute + 1]) + 1) / 2)])\n",
    "    \n",
    "    # as per the author's citation, we have transformed the input image\n",
    "    # (resize to 64×64, 256×256, 224×224)\n",
    "    pre_process = [(64, 64), (256, 256), (224, 224)]\n",
    "    mean_normalize = (0.485, 0.456, 0.406)\n",
    "    std_normalize = (0.229, 0.224, 0.225)\n",
    "    \n",
    "    if augment:\n",
    "        transform = A.Compose([\n",
    "            A.Resize(pre_process[0][0], pre_process[0][1]),\n",
    "            A.Resize(pre_process[1][0], pre_process[1][1]),\n",
    "            A.RandomCrop(width=pre_process[2][0], height=pre_process[2][1]),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.Normalize(mean=mean_normalize, std=std_normalize)\n",
    "        ])\n",
    "    \n",
    "    else:\n",
    "        transform = A.Compose([\n",
    "            A.Resize(pre_process[0][0], pre_process[0][1]),\n",
    "            A.Resize(pre_process[1][0], pre_process[1][1]),\n",
    "            A.CenterCrop(width=pre_process[2][0], height=pre_process[2][1]),\n",
    "            A.Normalize(mean=mean_normalize, std=std_normalize)\n",
    "        ])\n",
    "    if num_samples == -1:\n",
    "        num_samples = len(imgs)\n",
    "    else:\n",
    "        print(\"Num. of data ({}) is used for debugging\".format(num_samples))\n",
    "        \n",
    "    def load_func(i):\n",
    "        # crop the aligned & cropped 178×218 images to 128x128\n",
    "        cx = 121\n",
    "        cy = 89\n",
    "        c_pixels = 64\n",
    "        img = Image.open(imgs[i])\n",
    "        img = np.array(img.convert('RGB'))\n",
    "        img = img[cx - c_pixels:cx+c_pixels, cy-c_pixels:cy+c_pixels]\n",
    "        # transform\n",
    "        transformed_image = transform(image=img)['image'].transpose(2, 0, 1)\n",
    "        return transformed_image, labels[imgs[i]]\n",
    "    return data_iterator_simple(load_func, num_samples, batch_size, shuffle=shuffle, rng=rng, with_file_cache=False)"
   ]
  },
  {
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> f133105 (added support for download and split the celebA dataset)
=======
>>>>>>> f133105 (added support for download and split the celebA dataset)
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_celeba_dataset(img_path, attr_path, out_dir, split=\"test\"):\n",
    "    \n",
    "    \"\"\"\n",
    "    split the celebA dataset\n",
    "    Args:\n",
    "        img_path (str) : image path directory \n",
    "        attr_path (str) : celebA attribute file path (ex: list_attr_celeba.txt)\n",
    "        out_dir (str) : Path where the split data to be saved\n",
    "        split (string) : split the dataset depends on the split attribute(train, valid, and test)\n",
    "    \"\"\"\n",
    "    # as per the author's citation, we are splitting the dataset\n",
    "    train_beg = 0  # train starts from\n",
    "    valid_beg = 162770  # valid starts from\n",
    "    test_beg = 182610  # test starts from\n",
    "    \n",
    "    label_file = open(attr_path, 'r')\n",
    "    label_file = label_file.readlines()\n",
    "    \n",
    "    # skipping the first two rows for header\n",
    "    total_samples = len(label_file) - 2\n",
    "    if split == 'train':\n",
    "        number_samples = valid_beg - train_beg\n",
    "        beg = train_beg\n",
    "    \n",
    "    elif split == 'valid':\n",
    "        number_samples = test_beg - valid_beg\n",
    "        beg = valid_beg\n",
    "    \n",
    "    elif split == 'test':\n",
    "        number_samples = total_samples - test_beg\n",
    "        beg = test_beg\n",
    "    else:\n",
    "        print('Error')\n",
    "        return\n",
    "    \n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "    \n",
    "    for i in range(beg + 2, beg + number_samples + 2):\n",
    "        temp = label_file[i].strip().split()\n",
    "        src_dir = os.path.join(img_path,temp[0])\n",
    "        dst_dir = os.path.join(out_dir,temp[0])\n",
    "        shutil.copy(src_dir, dst_dir)\n",
    "    print(\"splitting completed\")\n",
    "        "
   ]
  },
  {
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 80cfa23 (added tutorial notebook for gan debiasing - Part2)
=======
>>>>>>> f133105 (added support for download and split the celebA dataset)
=======
>>>>>>> 80cfa23 (added tutorial notebook for gan debiasing - Part2)
=======
>>>>>>> f133105 (added support for download and split the celebA dataset)
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train Attribute Classifier\n",
    "\n",
    "Let's start with importing basic modules to switch between CPU and GPU first."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
=======
>>>>>>> 80cfa23 (added tutorial notebook for gan debiasing - Part2)
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 13:21:58,004 [nnabla][INFO]: Initializing CUDA extension...\n",
      "2022-01-19 13:21:58,026 [nnabla][INFO]: Initializing cuDNN extension...\n"
     ]
    }
   ],
<<<<<<< HEAD
>>>>>>> 80cfa23 (added tutorial notebook for gan debiasing - Part2)
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> f133105 (added support for download and split the celebA dataset)
=======
>>>>>>> 80cfa23 (added tutorial notebook for gan debiasing - Part2)
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> f133105 (added support for download and split the celebA dataset)
   "source": [
    "from nnabla.ext_utils import get_extension_context\n",
    "context = \"cudnn\" # for gpu set context as 'cudnn' , cpu set context as 'cpu'\n",
    "device_id = 0\n",
    "ctx = get_extension_context(context, device_id=device_id)\n",
    "nn.set_default_context(ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's run Attribute Classifier \n",
    "\n",
    "For training Attribute Classifier, we have taken [ResNet-50](https://nnabla.org/pretrained-models/nnp_models/imagenet/Resnet-50/Resnet-50.nnp) pretrained on [ImageNet](https://image-net.org/) as the base architecture. We replaced the linear layer in ResNet with two linear layers with the hidden layer of size 2048. Dropout and ReLU are applied between these. We train all models with binary cross entropy loss for 20 epochs with a batch size of 32. We use the [Adam](https://arxiv.org/abs/1412.6980) optimizer with a learning rate of 1e-3.\n",
    "\n",
    "\n",
    "We have trained the Attribute Classifier and saved model with best accuracy on validation set. If you want to train the baseline Attribute Classifier from the scratch please refer to our GitHub page and follow the steps.\n",
    "\n",
    "\n",
    "Now let us get the pre-trained weights for the classifier and load the model. Then we shall check model fairness.\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the celeba dataset and unzip\n",
    "URL = \"https://www.dropbox.com/s/d1kjpkqklf0uw77/celeba.zip?dl=0\"\n",
    "ZIP_FILE= \"./data/celeba.zip\"\n",
    "!mkdir -p ./data/\n",
    "!wget -N $URL -O $ZIP_FILE\n",
    "!unzip $ZIP_FILE -d ./data/\n",
    "!rm $ZIP_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.clear_parameters()\n",
    "# download the pre-trained weights\n",
    "\n",
    "attribute_classifier_model = clf.attribute_classifier(model_load_path=\n",
    "                                                      r'Arched_Eyebrows/baseline.h5')\n",
    "# split the dataset\n",
    "split_celeba_dataset(r'./data/celeba/images', r'./data/celeba/list_attr_celeba.txt', r'./test',split=\"test\")\n",
    "# load dataloader\n",
    "test = data_iterator_celeba(img_path= r'./test',\n",
    "                            attr_path= r'./data/celeba/list_attr_celeba.txt',\n",
    "                            batch_size=32, target_attribute=1, protected_attribute=20)\n",
    "cal_thresh = pickle.load(open(r'Arched_Eyebrows/val_baseline.pkl', 'rb'))['cal_thresh']"
=======
   "execution_count": 5,
=======
   "execution_count": null,
>>>>>>> f133105 (added support for download and split the celebA dataset)
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the celeba dataset and unzip\n",
    "URL = \"https://www.dropbox.com/s/d1kjpkqklf0uw77/celeba.zip?dl=0\"\n",
    "ZIP_FILE= \"./data/celeba.zip\"\n",
    "!mkdir -p ./data/\n",
    "!wget -N $URL -O $ZIP_FILE\n",
    "!unzip $ZIP_FILE -d ./data/\n",
    "!rm $ZIP_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.clear_parameters()\n",
    "# download the pre-trained weights\n",
    "\n",
    "attribute_classifier_model = clf.attribute_classifier(model_load_path=\n",
    "                                                      r'Arched_Eyebrows/baseline.h5')\n",
    "# split the dataset\n",
    "split_celeba_dataset(r'./data/celeba/images', r'./data/celeba/list_attr_celeba.txt', r'./test',split=\"test\")\n",
    "# load dataloader\n",
    "test = data_iterator_celeba(img_path= r'./test',\n",
    "                            attr_path= r'./data/celeba/list_attr_celeba.txt',\n",
    "                            batch_size=32, target_attribute=1, protected_attribute=20)\n",
<<<<<<< HEAD
    "cal_thresh = pickle.load(open(r'/results_baseline/Arched_Eyebrows/best/val_results.pkl', 'rb'))['cal_thresh']"
>>>>>>> 80cfa23 (added tutorial notebook for gan debiasing - Part2)
=======
    "cal_thresh = pickle.load(open(r'Arched_Eyebrows/val_baseline.pkl', 'rb'))['cal_thresh']"
>>>>>>> 29eb436 (renamed the image name & tutorial title)
=======
   "execution_count": 5,
=======
   "execution_count": null,
>>>>>>> f133105 (added support for download and split the celebA dataset)
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the celeba dataset and unzip\n",
    "URL = \"https://www.dropbox.com/s/d1kjpkqklf0uw77/celeba.zip?dl=0\"\n",
    "ZIP_FILE= \"./data/celeba.zip\"\n",
    "!mkdir -p ./data/\n",
    "!wget -N $URL -O $ZIP_FILE\n",
    "!unzip $ZIP_FILE -d ./data/\n",
    "!rm $ZIP_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.clear_parameters()\n",
    "# download the pre-trained weights\n",
    "\n",
    "attribute_classifier_model = clf.attribute_classifier(model_load_path=\n",
    "                                                      r'Arched_Eyebrows/baseline.h5')\n",
    "# split the dataset\n",
    "split_celeba_dataset(r'./data/celeba/images', r'./data/celeba/list_attr_celeba.txt', r'./test',split=\"test\")\n",
    "# load dataloader\n",
    "test = data_iterator_celeba(img_path= r'./test',\n",
    "                            attr_path= r'./data/celeba/list_attr_celeba.txt',\n",
    "                            batch_size=32, target_attribute=1, protected_attribute=20)\n",
<<<<<<< HEAD
    "cal_thresh = pickle.load(open(r'/results_baseline/Arched_Eyebrows/best/val_results.pkl', 'rb'))['cal_thresh']"
>>>>>>> 80cfa23 (added tutorial notebook for gan debiasing - Part2)
=======
    "cal_thresh = pickle.load(open(r'Arched_Eyebrows/val_baseline.pkl', 'rb'))['cal_thresh']"
>>>>>>> 29eb436 (renamed the image name & tutorial title)
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Attribute classifier fairness\n",
    "\n",
    "\n",
    "Let's start our investigation of classifier model fairness by analyzing the predictions made on test set. In this tutorial, we use average precission (AP) metric to measure classifier accuracy and three metrics to compute model fairness. First, we measure the [difference in equality of opportunity](https://arxiv.org/abs/2004.01355) (DEO), i.e. the absolute difference in False Negative Rate (FNR) for protected attribute group. As our second fairness metric, we use the [bias amplification](https://arxiv.org/abs/2102.12594) (BA) metric proposed by Wang and Russakovsky. Intuitively, BA measures how much more often a target attribute is predicted with a protected attribute than the ground truth value. Both DEO and BA fluctuate based on the chosen classification threshold. Therefore, as our final fairness metric, we use a threshold-invariant metric that measures the divergence between score distributions [(KL)](https://arxiv.org/abs/2006.10667).\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
=======
>>>>>>> 80cfa23 (added tutorial notebook for gan debiasing - Part2)
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results: \n",
      "AP : {:.1f} 76.91481855297975\n",
      "DEO : {:.1f} 60.36789540824758\n",
      "BA : {:.1f} 3.15834272995464\n",
      "KL : {:.1f} 1.40938573424393\n"
     ]
    }
   ],
<<<<<<< HEAD
>>>>>>> 80cfa23 (added tutorial notebook for gan debiasing - Part2)
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> f133105 (added support for download and split the celebA dataset)
=======
>>>>>>> 80cfa23 (added tutorial notebook for gan debiasing - Part2)
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> f133105 (added support for download and split the celebA dataset)
   "source": [
    "test_targets, test_scores = attribute_classifier_model.get_scores(test)\n",
    "test_pred = np.where(test_scores > cal_thresh, 1, 0)\n",
    "\n",
    "ap = utils.get_average_precision(test_targets[:, 0], test_scores)\n",
    "deo = utils.get_difference_equality_opportunity(test_targets[:, 1],\n",
    "                                                     test_targets[:, 0], test_pred)\n",
    "ba = utils.get_bias_amplification(test_targets[:, 1],\n",
    "                                     test_targets[:, 0], test_pred)\n",
    "kl = utils.get_kl_divergence(test_targets[:, 1], test_targets[:, 0], test_scores)\n",
    "\n",
    "print('Test results: ')\n",
    "print('AP : {:.1f}', 100 * ap)\n",
    "print('DEO : {:.1f}', 100 * deo)\n",
    "print('BA : {:.1f}', 100 * ba)\n",
    "print('KL : {:.1f}', kl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Mitigate the bias using GAN's Latent Space De-biasing\n",
    "\n",
    "As mentioned earlier in this notebook, to debias the dataset we need to generate a balanced synthetic dataset.\n",
    "\n",
    "\n",
    "To generate images, we use a Progressive GAN from nnabla-examples page. This is with 512-D latent space trained on the CelebA dataset. We use 10000 synthetic images, labeled with baseline attribute classifiers and learn hyperplanes (for both target and protected ht, hg) in the latent space with scikit-learn’s linear SVM implementation.\n",
    "\n",
    "\n",
    "In this tutorial, Progressive GAN training is skipped intentionally. Please refer to our [GitHub page](https://github.com/sony/nnabla-examples/tree/master/GANs/pggan) for more info if you are interested in training PG GAN.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4. Train Attribute classifier with debiased dataset\n",
    "Well!\n",
    "Now we can train Attribute Classifier using both balanced synthetic dataset and original dataset. If you want to train the GAN-debiased model from the scratch please refer to our GitHub page and follow the steps.\n",
    "\n",
    "\n",
    "Let's get pre-trained weights of GAN-debiased model and check model fairness."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.clear_parameters()\n",
    "attribute_classifier_debiased_model = clf.attribute_classifier(model_load_path=r'Arched_Eyebrows/gan_data_debised.h5')\n",
    "cal_thresh = pickle.load(open(r'Arched_Eyebrows/val_gan_data_debised.pkl', 'rb'))['cal_thresh']"
=======
   "execution_count": 7,
=======
   "execution_count": null,
>>>>>>> f133105 (added support for download and split the celebA dataset)
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.clear_parameters()\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "# download the pre-trained weights\n",
    "attribute_classifier_debiased_model = clf.attribute_classifier(model_load_path=r'/results_GAN/Arched_Eyebrows/best/best_acc.h5')\n",
    "cal_thresh = pickle.load(open(r'/results_GAN/Arched_Eyebrows/best/val_results.pkl', 'rb'))['cal_thresh']"
>>>>>>> 80cfa23 (added tutorial notebook for gan debiasing - Part2)
=======
    "attribute_classifier_debiased_model = clf.attribute_classifier(model_load_path=r'Arched_Eyebrows/gan_data_debiased.h5')\n",
    "cal_thresh = pickle.load(open(r'Arched_Eyebrows/val_gan_data_debiased.pkl', 'rb'))['cal_thresh']"
>>>>>>> 29eb436 (renamed the image name & tutorial title)
=======
    "attribute_classifier_debiased_model = clf.attribute_classifier(model_load_path=r'Arched_Eyebrows/gan_data_debised.h5')\n",
    "cal_thresh = pickle.load(open(r'Arched_Eyebrows/val_gan_data_debised.pkl', 'rb'))['cal_thresh']"
>>>>>>> f133105 (added support for download and split the celebA dataset)
=======
   "execution_count": 7,
=======
   "execution_count": null,
>>>>>>> f133105 (added support for download and split the celebA dataset)
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.clear_parameters()\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "# download the pre-trained weights\n",
    "attribute_classifier_debiased_model = clf.attribute_classifier(model_load_path=r'/results_GAN/Arched_Eyebrows/best/best_acc.h5')\n",
    "cal_thresh = pickle.load(open(r'/results_GAN/Arched_Eyebrows/best/val_results.pkl', 'rb'))['cal_thresh']"
>>>>>>> 80cfa23 (added tutorial notebook for gan debiasing - Part2)
=======
    "attribute_classifier_debiased_model = clf.attribute_classifier(model_load_path=r'Arched_Eyebrows/gan_data_debiased.h5')\n",
    "cal_thresh = pickle.load(open(r'Arched_Eyebrows/val_gan_data_debiased.pkl', 'rb'))['cal_thresh']"
>>>>>>> 29eb436 (renamed the image name & tutorial title)
=======
    "attribute_classifier_debiased_model = clf.attribute_classifier(model_load_path=r'Arched_Eyebrows/gan_data_debised.h5')\n",
    "cal_thresh = pickle.load(open(r'Arched_Eyebrows/val_gan_data_debised.pkl', 'rb'))['cal_thresh']"
>>>>>>> f133105 (added support for download and split the celebA dataset)
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Fairness "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
=======
>>>>>>> 80cfa23 (added tutorial notebook for gan debiasing - Part2)
   "execution_count": 8,
   "metadata": {},
   "outputs": [
=======
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBtwxoAiHWnh"
      },
      "source": [
        "## GAN Data-Debiasing\n",
        "\n",
        "### Table of contents :\n",
        "1. [Introduction](#1.-Introduction)\n",
        "2. [Train Attribute Classifier](#2.-Train-Attribute-Classifier)\n",
        "\t* [Compute Fairness](#Compute-fairness-of-Attribute-classifier)\n",
        "3. [Mitigate bias using GAN's Latent Space De-biasing.](#3.-Mitigate-the-bias-using-GAN's-Latent-Space-De-biasing)\n",
        "4. [Train Attribute classifier with debiased dataset](#4.-Train-Attribute-classifier-with-debiased-dataset)\n",
        "\t* [Compute Fairness](#Compute-Fairness)\n",
        "5. [Summary](#5.-Summary)"
      ],
      "id": "PBtwxoAiHWnh"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4Xrx9a6HWnn"
      },
      "source": [
        "### 1. Introduction\n",
        "\n",
        "\n",
        "Welcome !\n",
        "\n",
        "\n",
        "Application of Deep Learning for vision problems has proliferated in recent times. Its widespread application necessitates need for \"Fairness\". Deep Learning models trained with only labels as beacons possibly learn spurious correlations between labels and certain features [or attributes].\n",
        "\n",
        "\n",
        "for ex., if we train a model to classify \"people wearing hats\", the classifier may inadvertantly associate sunglasses with hats if the dataset has narrow distribution of mostly outdoor images (people often wear both hats and sunglasses together outdoors and take them off indoors). Because of this correlation in the training data classifier trained to recognize a hat may rely on the presence of glasses. As a result, the classifier may fail to recognize a hat in the absence of sunglasses. Capturing perfectly balanced dataset is not feasible in many cases. In such cases, as shown in this notebook, one could train classifiers while mitigating biases that stem from these correlations, by using [Fair Attribute Classification through Latent Space De-biasing](https://arxiv.org/abs/2012.01469).\n",
        "\n",
        "### Preparation\n",
        "Let's start by installing nnabla and accessing [nnabla-examples repository](https://github.com/sony/nnabla-examples). If you're running on Colab, make sure that your Runtime setting is set as GPU, which can be set up from the top menu (Runtime → change runtime type), and make sure to click **Connect** on the top right-hand side of the screen before you start.\n",
        "\n",
        "Before we go into detailed explanation, here is a sneak peek into the steps involved in the process:\n"
      ],
      "id": "E4Xrx9a6HWnn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLnhu1hJHWnp"
      },
      "outputs": [],
      "source": [
        "# Preparation\n",
        "!git clone https://github.com/sony/nnabla-examples.git\n",
        "%cd nnabla-examples/responsible_ai/gan_data_debiased\n",
        "!pip install albumentations\n",
        "\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "img = cv2.imread('images/gan_data_debiasing_workflow.png')\n",
        "cv2_imshow(img)"
      ],
      "id": "oLnhu1hJHWnp"
    },
>>>>>>> 896e041 (Recover Jupyer file and set PU defalt)
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wetcJO2MHWnq"
      },
      "source": [
        "As illustrated in the picture, we use [GAN](https://arxiv.org/abs/1406.2661) technique to generate realistic-looking images and perturb these images in the underlying latent space to generate training data that is balanced for each protected attribute. Then we augment the original dataset with this generated data and empirically demonstrate that target classifiers trained on the augmented dataset exhibits a number of both quantitative and qualitative benefits.\n",
        "\n",
        "\n",
        "Let's first train a baseline attribute classifier with original [celebA](https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) dataset, analyze model fairness. Then we shall train the target attribute classifier with a balanced dataset and original dataset to make the model fair if fairness metric is not satisfactory.\n"
      ],
      "id": "wetcJO2MHWnq"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_UZF9i9HWnr"
      },
      "source": [
        "#### Preparation"
      ],
      "id": "v_UZF9i9HWnr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsAHLKH9HWnr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import pickle\n",
        "import shutil\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import albumentations as A\n",
        "import nnabla as nn\n",
        "from nnabla.ext_utils import get_extension_context\n",
        "from nnabla.utils.data_iterator import data_iterator_simple\n",
        "import classifier as clf\n",
        "from utils import utils"
      ],
      "id": "gsAHLKH9HWnr"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b57DwcwfHWns"
      },
      "source": [
        "Let us train an `Arched Eyebrow` classifier that is not dependent on gender expression. For this, we require a dataset that has target labels (`Arched eyebrow`) as well as gender expression labels. [celebA](https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) is a dataset with 2,022,599 images of celebrity faces, each with 40 binary attributes labels. We assume the `Male` attribute corresponds to gender expression and the target attribute is `Arched Eyebrow`.\n",
        "\n",
        "\n",
        "NNabla provides various utilities for using data for training/validation. Here, we will use NNabla data_iterator_simple.\n"
      ],
      "id": "b57DwcwfHWns"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIvsH8w8HWnt"
      },
      "outputs": [],
      "source": [
        "def data_iterator_celeba(img_path,attr_path, batch_size,\n",
        "                         target_attribute=1,protected_attribute=20,\n",
        "                         num_samples=-1,augment=False, shuffle=False, rng=None):\n",
        "    \"\"\"\n",
        "    create celebA data iterator\n",
        "    Args:\n",
        "        img_path (str) : image path directory \n",
        "        attr_path (str) : celebA attribute file path (ex: list_attr_celeba.txt)\n",
        "        batch_size (int) :  number of samples contained in each generated batch\n",
        "        target_attribute (int) : target attribute (ex: Arched EyeBrows (1), Bushy Eyebrows(12), smilling (31),etc..)\n",
        "        protected_attribute (int): protected attribute (ex: Male (20), Pale_Skin (26))\n",
        "        num_samples (int) : number of samples taken in data loader\n",
        "                            (if num_samples=-1, it will take all the images in the dataset)\n",
        "        augment (bool) : data augmentation (True for training)\n",
        "        shuffle (bool) : shuffle the data (True /False)\n",
        "        rng : None\n",
        "    Returns:\n",
        "        simple data iterator\n",
        "    \"\"\"\n",
        "    \n",
        "    imgs = glob.glob(\"{}/*.jpg\".format(img_path))\n",
        "    label_file = open(attr_path, 'r')\n",
        "    label_file = label_file.readlines()\n",
        "    labels = {}\n",
        "    # skipping first two rows(headers)\n",
        "    for i in range(2, len(label_file)):\n",
        "        temp = label_file[i].strip().split()\n",
        "        labels[os.path.join(img_path, temp[0])] = np.array(\n",
        "            [int((int(temp[target_attribute + 1]) + 1) / 2), int((int(temp[protected_attribute + 1]) + 1) / 2)])\n",
        "    \n",
        "    # as per the author's citation, we have transformed the input image\n",
        "    # (resize to 64×64, 256×256, 224×224)\n",
        "    pre_process = [(64, 64), (256, 256), (224, 224)]\n",
        "    mean_normalize = (0.485, 0.456, 0.406)\n",
        "    std_normalize = (0.229, 0.224, 0.225)\n",
        "    \n",
        "    if augment:\n",
        "        transform = A.Compose([\n",
        "            A.Resize(pre_process[0][0], pre_process[0][1]),\n",
        "            A.Resize(pre_process[1][0], pre_process[1][1]),\n",
        "            A.RandomCrop(width=pre_process[2][0], height=pre_process[2][1]),\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.Normalize(mean=mean_normalize, std=std_normalize)\n",
        "        ])\n",
        "    \n",
        "    else:\n",
        "        transform = A.Compose([\n",
        "            A.Resize(pre_process[0][0], pre_process[0][1]),\n",
        "            A.Resize(pre_process[1][0], pre_process[1][1]),\n",
        "            A.CenterCrop(width=pre_process[2][0], height=pre_process[2][1]),\n",
        "            A.Normalize(mean=mean_normalize, std=std_normalize)\n",
        "        ])\n",
        "    if num_samples == -1:\n",
        "        num_samples = len(imgs)\n",
        "    else:\n",
        "        print(\"Num. of data ({}) is used for debugging\".format(num_samples))\n",
        "        \n",
        "    def load_func(i):\n",
        "        # crop the aligned & cropped 178×218 images to 128x128\n",
        "        cx = 121\n",
        "        cy = 89\n",
        "        c_pixels = 64\n",
        "        img = Image.open(imgs[i])\n",
        "        img = np.array(img.convert('RGB'))\n",
        "        img = img[cx - c_pixels:cx+c_pixels, cy-c_pixels:cy+c_pixels]\n",
        "        # transform\n",
        "        transformed_image = transform(image=img)['image'].transpose(2, 0, 1)\n",
        "        return transformed_image, labels[imgs[i]]\n",
        "    return data_iterator_simple(load_func, num_samples, batch_size, shuffle=shuffle, rng=rng, with_file_cache=False)"
      ],
      "id": "SIvsH8w8HWnt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HltRTgTWHWnu"
      },
      "outputs": [],
      "source": [
        "def split_celeba_dataset(img_path, attr_path, out_dir, split=\"test\"):\n",
        "    \n",
        "    \"\"\"\n",
        "    split the celebA dataset\n",
        "    Args:\n",
        "        img_path (str) : image path directory \n",
        "        attr_path (str) : celebA attribute file path (ex: list_attr_celeba.txt)\n",
        "        out_dir (str) : Path where the split data to be saved\n",
        "        split (string) : split the dataset depends on the split attribute(train, valid, and test)\n",
        "    \"\"\"\n",
        "    # as per the author's citation, we are splitting the dataset\n",
        "    train_beg = 0  # train starts from\n",
        "    valid_beg = 162770  # valid starts from\n",
        "    test_beg = 182610  # test starts from\n",
        "    \n",
        "    label_file = open(attr_path, 'r')\n",
        "    label_file = label_file.readlines()\n",
        "    \n",
        "    # skipping the first two rows for header\n",
        "    total_samples = len(label_file) - 2\n",
        "    if split == 'train':\n",
        "        number_samples = valid_beg - train_beg\n",
        "        beg = train_beg\n",
        "    \n",
        "    elif split == 'valid':\n",
        "        number_samples = test_beg - valid_beg\n",
        "        beg = valid_beg\n",
        "    \n",
        "    elif split == 'test':\n",
        "        number_samples = total_samples - test_beg\n",
        "        beg = test_beg\n",
        "    else:\n",
        "        print('Error')\n",
        "        return\n",
        "    \n",
        "    if not os.path.exists(out_dir):\n",
        "        os.makedirs(out_dir)\n",
        "    \n",
        "    for i in range(beg + 2, beg + number_samples + 2):\n",
        "        temp = label_file[i].strip().split()\n",
        "        src_dir = os.path.join(img_path,temp[0])\n",
        "        dst_dir = os.path.join(out_dir,temp[0])\n",
        "        shutil.copy(src_dir, dst_dir)\n",
        "    print(\"splitting completed\")\n",
        "        "
      ],
      "id": "HltRTgTWHWnu"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSWa0yKxHWnw"
      },
      "source": [
        "### 2. Train Attribute Classifier\n",
        "\n",
        "Let's start with importing basic modules for GPU first."
      ],
      "id": "kSWa0yKxHWnw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ih6Km9Q0HWnx"
      },
      "outputs": [],
      "source": [
        "from nnabla.ext_utils import get_extension_context\n",
        "ctx = get_extension_context('cudnn')\n",
        "nn.set_default_context(ctx)"
      ],
      "id": "Ih6Km9Q0HWnx"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbgOQzfLHWny"
      },
      "source": [
        "#### Now let's run Attribute Classifier \n",
        "\n",
        "For training Attribute Classifier, we have taken [ResNet-50](https://nnabla.org/pretrained-models/nnp_models/imagenet/Resnet-50/Resnet-50.nnp) pretrained on [ImageNet](https://image-net.org/) as the base architecture. We replaced the linear layer in ResNet with two linear layers with the hidden layer of size 2048. Dropout and ReLU are applied between these. We train all models with binary cross entropy loss for 20 epochs with a batch size of 32. We use the [Adam](https://arxiv.org/abs/1412.6980) optimizer with a learning rate of 1e-3.\n",
        "\n",
        "\n",
        "We have trained the Attribute Classifier and saved model with best accuracy on validation set. If you want to train the baseline Attribute Classifier from the scratch please refer to our GitHub page and follow the steps.\n",
        "\n",
        "\n",
        "Now let us get the pre-trained weights for the classifier and load the model. Then we shall check model fairness.\n"
      ],
      "id": "tbgOQzfLHWny"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rkd32-SaHWnz"
      },
      "outputs": [],
      "source": [
        "# download the celeba dataset and unzip\n",
        "URL = \"https://www.dropbox.com/s/d1kjpkqklf0uw77/celeba.zip?dl=0\"\n",
        "ZIP_FILE= \"./data/celeba.zip\"\n",
        "!mkdir -p ./data/\n",
        "!wget -N $URL -O $ZIP_FILE\n",
        "!unzip $ZIP_FILE -d ./data/\n",
        "!rm $ZIP_FILE"
      ],
      "id": "Rkd32-SaHWnz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RD204iLsHWnz"
      },
      "outputs": [],
      "source": [
        "nn.clear_parameters()\n",
        "# download the pre-trained weights\n",
        "\n",
        "attribute_classifier_model = clf.attribute_classifier(model_load_path=\n",
        "                                                      r'Arched_Eyebrows/baseline.h5')\n",
        "# split the dataset\n",
        "split_celeba_dataset(r'./data/celeba/images', r'./data/celeba/list_attr_celeba.txt', r'./test',split=\"test\")\n",
        "# load dataloader\n",
        "test = data_iterator_celeba(img_path= r'./test',\n",
        "                            attr_path= r'./data/celeba/list_attr_celeba.txt',\n",
        "                            batch_size=32, target_attribute=1, protected_attribute=20)\n",
        "cal_thresh = pickle.load(open(r'Arched_Eyebrows/val_baseline.pkl', 'rb'))['cal_thresh']"
      ],
      "id": "RD204iLsHWnz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvVpE3JqHWn0"
      },
      "source": [
        "### Compute Attribute classifier fairness\n",
        "\n",
        "\n",
        "Let's start our investigation of classifier model fairness by analyzing the predictions made on test set. In this tutorial, we use average precission (AP) metric to measure classifier accuracy and three metrics to compute model fairness. First, we measure the [difference in equality of opportunity](https://arxiv.org/abs/2004.01355) (DEO), i.e. the absolute difference in False Negative Rate (FNR) for protected attribute group. As our second fairness metric, we use the [bias amplification](https://arxiv.org/abs/2102.12594) (BA) metric proposed by Wang and Russakovsky. Intuitively, BA measures how much more often a target attribute is predicted with a protected attribute than the ground truth value. Both DEO and BA fluctuate based on the chosen classification threshold. Therefore, as our final fairness metric, we use a threshold-invariant metric that measures the divergence between score distributions [(KL)](https://arxiv.org/abs/2006.10667).\n"
      ],
      "id": "nvVpE3JqHWn0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EV_XMsJjHWn0"
      },
      "outputs": [],
      "source": [
        "test_targets, test_scores = attribute_classifier_model.get_scores(test)\n",
        "test_pred = np.where(test_scores > cal_thresh, 1, 0)\n",
        "\n",
        "ap = utils.get_average_precision(test_targets[:, 0], test_scores)\n",
        "deo = utils.get_difference_equality_opportunity(test_targets[:, 1],\n",
        "                                                     test_targets[:, 0], test_pred)\n",
        "ba = utils.get_bias_amplification(test_targets[:, 1],\n",
        "                                     test_targets[:, 0], test_pred)\n",
        "kl = utils.get_kl_divergence(test_targets[:, 1], test_targets[:, 0], test_scores)\n",
        "\n",
        "print('Test results: ')\n",
        "print('AP : {:.1f}', 100 * ap)\n",
        "print('DEO : {:.1f}', 100 * deo)\n",
        "print('BA : {:.1f}', 100 * ba)\n",
        "print('KL : {:.1f}', kl)"
      ],
      "id": "EV_XMsJjHWn0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gN0d3T0SHWn0"
      },
      "source": [
        "### 3. Mitigate the bias using GAN's Latent Space De-biasing\n",
        "\n",
        "As mentioned earlier in this notebook, to debias the dataset we need to generate a balanced synthetic dataset.\n",
        "\n",
        "\n",
        "To generate images, we use a Progressive GAN from nnabla-examples page. This is with 512-D latent space trained on the CelebA dataset. We use 10000 synthetic images, labeled with baseline attribute classifiers and learn hyperplanes (for both target and protected ht, hg) in the latent space with scikit-learn’s linear SVM implementation.\n",
        "\n",
        "\n",
        "In this tutorial, Progressive GAN training is skipped intentionally. Please refer to our [GitHub page](https://github.com/sony/nnabla-examples/tree/master/GANs/pggan) for more info if you are interested in training PG GAN.\n",
        "\n"
      ],
      "id": "gN0d3T0SHWn0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VfvCZnoHWn1"
      },
      "source": [
        "\n",
        "### 4. Train Attribute classifier with debiased dataset\n",
        "Well!\n",
        "Now we can train Attribute Classifier using both balanced synthetic dataset and original dataset. If you want to train the GAN-debiased model from the scratch please refer to our GitHub page and follow the steps.\n",
        "\n",
        "\n",
        "Let's get pre-trained weights of GAN-debiased model and check model fairness."
      ],
      "id": "9VfvCZnoHWn1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFxaFeNoHWn1"
      },
      "outputs": [],
      "source": [
        "nn.clear_parameters()\n",
        "attribute_classifier_debiased_model = clf.attribute_classifier(model_load_path=r'Arched_Eyebrows/gan_data_debised.h5')\n",
        "cal_thresh = pickle.load(open(r'Arched_Eyebrows/val_gan_data_debised.pkl', 'rb'))['cal_thresh']"
      ],
      "id": "PFxaFeNoHWn1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRrzwqK3HWn1"
      },
      "source": [
        "### Compute Fairness "
      ],
      "id": "MRrzwqK3HWn1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RED9xH5KHWn1"
      },
      "outputs": [],
      "source": [
        "test_targets, test_scores = attribute_classifier_debiased_model.get_scores(test)\n",
        "test_pred = np.where(test_scores > cal_thresh, 1, 0)\n",
        "\n",
        "ap = utils.get_average_precision(test_targets[:, 0], test_scores)\n",
        "deo = utils.get_difference_equality_opportunity(test_targets[:, 1],\n",
        "                                                     test_targets[:, 0], test_pred)\n",
        "ba = utils.get_bias_amplification(test_targets[:, 1],\n",
        "                                     test_targets[:, 0], test_pred)\n",
        "kl = utils.get_kl_divergence(test_targets[:, 1], test_targets[:, 0], test_scores)\n",
        "\n",
        "print('Test results: ')\n",
        "print('AP : {:.1f}', 100 * ap)\n",
        "print('DEO : {:.1f}', 100 * deo)\n",
        "print('BA : {:.1f}', 100 * ba)\n",
        "print('KL : {:.1f}', kl)"
      ],
      "id": "RED9xH5KHWn1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQB2EqgzHWn2"
      },
      "source": [
        "If you observe above results with four metrics, GAN-debiased model performs better on all three fairness metrics: DEO, BA, and KL Divergence, while maintaining comparable AP over the baseline `Arched Brows` Classifier."
      ],
      "id": "XQB2EqgzHWn2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ua9a635HWn2"
      },
      "source": [
        "### 5. Summary\n",
        "\n",
        "In this tutorial, we have shown how GAN-based data augmentation method could be employed to train a fairer Attribute Classifier in the presense of correlation between target label (Arched eyebrows) and a protected attribute (Gender Expression). In the same way, you may try different attribute classifiers. If there is bias in baseline Attribute Classifier model, try to balance the training data with an approach like GAN for data augmentation. To train different attribute classifiers, please refer to our GitHub page and follow the steps."
      ],
      "id": "-Ua9a635HWn2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdKkM-y-HWn2"
      },
      "source": [
        "### References\n",
        "1. [Fair Attribute Classification through Latent Space De-biasing ](https://arxiv.org/abs/2012.01469)\n",
        "2. [Generative Adversarial Networks](https://arxiv.org/abs/1406.2661)\n",
        "3. [Large-scale CelebFaces Attributes (CelebA) Dataset](https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html)\n",
        "4. [Adam: A Method for Stochastic Optimization](https://arxiv.org/abs/1412.6980)\n",
        "5. [FairALM: Augmented Lagrangian Method for Training Fair Models with Little Regret](https://arxiv.org/abs/2004.01355)\n",
        "6. [Directional Bias Amplification](https://arxiv.org/abs/2102.12594)\n",
        "7. [Towards Threshold Invariant Fair Classification](https://arxiv.org/abs/2006.10667)"
      ],
      "id": "pdKkM-y-HWn2"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "gan_data_debiasing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
<<<<<<< HEAD
   ],
<<<<<<< HEAD
>>>>>>> 80cfa23 (added tutorial notebook for gan debiasing - Part2)
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> f133105 (added support for download and split the celebA dataset)
=======
>>>>>>> 80cfa23 (added tutorial notebook for gan debiasing - Part2)
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> f133105 (added support for download and split the celebA dataset)
   "source": [
    "test_targets, test_scores = attribute_classifier_debiased_model.get_scores(test)\n",
    "test_pred = np.where(test_scores > cal_thresh, 1, 0)\n",
    "\n",
    "ap = utils.get_average_precision(test_targets[:, 0], test_scores)\n",
    "deo = utils.get_difference_equality_opportunity(test_targets[:, 1],\n",
    "                                                     test_targets[:, 0], test_pred)\n",
    "ba = utils.get_bias_amplification(test_targets[:, 1],\n",
    "                                     test_targets[:, 0], test_pred)\n",
    "kl = utils.get_kl_divergence(test_targets[:, 1], test_targets[:, 0], test_scores)\n",
    "\n",
    "print('Test results: ')\n",
    "print('AP : {:.1f}', 100 * ap)\n",
    "print('DEO : {:.1f}', 100 * deo)\n",
    "print('BA : {:.1f}', 100 * ba)\n",
    "print('KL : {:.1f}', kl)"
   ]
=======
>>>>>>> 896e041 (Recover Jupyer file and set PU defalt)
=======
    "5. [Summary](#5.-Summary)"
   ]
>>>>>>> 718c992 (1. added pre-trained weight links in notebook)
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E4Xrx9a6HWnn"
   },
   "source": [
    "### 1. Introduction\n",
    "\n",
    "\n",
    "Welcome !\n",
    "\n",
    "\n",
    "Application of Deep Learning for vision problems has proliferated in recent times. Its widespread application necessitates need for \"Fairness\". Deep Learning models trained with only labels as beacons possibly learn spurious correlations between labels and certain features [or attributes].\n",
    "\n",
    "\n",
    "for ex., if we train a model to classify \"people wearing hats\", the classifier may inadvertantly associate sunglasses with hats if the dataset has narrow distribution of mostly outdoor images (people often wear both hats and sunglasses together outdoors and take them off indoors). Because of this correlation in the training data classifier trained to recognize a hat may rely on the presence of glasses. As a result, the classifier may fail to recognize a hat in the absence of sunglasses. Capturing perfectly balanced dataset is not feasible in many cases. In such cases, as shown in this notebook, one could train classifiers while mitigating biases that stem from these correlations, by using [Fair Attribute Classification through Latent Space De-biasing](https://arxiv.org/abs/2012.01469).\n",
    "\n",
    "### Preparation\n",
    "Let's start by installing nnabla and accessing [nnabla-examples repository](https://github.com/sony/nnabla-examples). If you're running on Colab, make sure that your Runtime setting is set as GPU, which can be set up from the top menu (Runtime → change runtime type), and make sure to click **Connect** on the top right-hand side of the screen before you start.\n",
    "\n",
    "Before we go into detailed explanation, here is a sneak peek into the steps involved in the process:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oLnhu1hJHWnp"
   },
   "outputs": [],
   "source": [
    "# Preparation\n",
    "!git clone https://github.com/sony/nnabla-examples.git\n",
    "%cd nnabla-examples/responsible_ai/gan_data_debiased\n",
    "!pip install nnabla-ext-cuda100\n",
    "!pip install albumentations\n",
    "\n",
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n",
    "img = cv2.imread('images/gan_data_debiasing_workflow.png')\n",
    "cv2_imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wetcJO2MHWnq"
   },
   "source": [
    "As illustrated in the picture, we use [GAN](https://arxiv.org/abs/1406.2661) technique to generate realistic-looking images and perturb these images in the underlying latent space to generate training data that is balanced for each protected attribute. Then we augment the original dataset with this generated data and empirically demonstrate that target classifiers trained on the augmented dataset exhibits a number of both quantitative and qualitative benefits.\n",
    "\n",
    "\n",
    "Let's first train a baseline attribute classifier with original [celebA](https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) dataset, analyze model fairness. Then we shall train the target attribute classifier with a balanced dataset and original dataset to make the model fair if fairness metric is not satisfactory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gsAHLKH9HWnr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import shutil\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "import nnabla as nn\n",
    "from nnabla.ext_utils import get_extension_context\n",
    "from nnabla.utils.data_iterator import data_iterator_simple\n",
    "import classifier as clf\n",
    "from utils import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b57DwcwfHWns"
   },
   "source": [
    "Let us train an `Arched Eyebrow` classifier that is not dependent on gender expression. For this, we require a dataset that has target labels (`Arched eyebrow`) as well as gender expression labels. [celebA](https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) is a dataset with 2,022,599 images of celebrity faces, each with 40 binary attributes labels. We assume the `Male` attribute corresponds to gender expression and the target attribute is `Arched Eyebrow`.\n",
    "\n",
    "\n",
    "NNabla provides various utilities for using data for training/validation. Here, we will use NNabla data_iterator_simple.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SIvsH8w8HWnt"
   },
   "outputs": [],
   "source": [
    "def data_iterator_celeba(img_path,attr_path, batch_size,\n",
    "                         target_attribute=1,protected_attribute=20,\n",
    "                         num_samples=-1,augment=False, shuffle=False, rng=None):\n",
    "    \"\"\"\n",
    "    create celebA data iterator\n",
    "    Args:\n",
    "        img_path (str) : image path directory \n",
    "        attr_path (str) : celebA attribute file path (ex: list_attr_celeba.txt)\n",
    "        batch_size (int) :  number of samples contained in each generated batch\n",
    "        target_attribute (int) : target attribute (ex: Arched EyeBrows (1), Bushy Eyebrows(12), smilling (31),etc..)\n",
    "        protected_attribute (int): protected attribute (ex: Male (20), Pale_Skin (26))\n",
    "        num_samples (int) : number of samples taken in data loader\n",
    "                            (if num_samples=-1, it will take all the images in the dataset)\n",
    "        augment (bool) : data augmentation (True for training)\n",
    "        shuffle (bool) : shuffle the data (True /False)\n",
    "        rng : None\n",
    "    Returns:\n",
    "        simple data iterator\n",
    "    \"\"\"\n",
    "    \n",
    "    imgs = glob.glob(\"{}/*.jpg\".format(img_path))\n",
    "    label_file = open(attr_path, 'r')\n",
    "    label_file = label_file.readlines()\n",
    "    labels = {}\n",
    "    # skipping first two rows(headers)\n",
    "    for i in range(2, len(label_file)):\n",
    "        temp = label_file[i].strip().split()\n",
    "        labels[os.path.join(img_path, temp[0])] = np.array(\n",
    "            [int((int(temp[target_attribute + 1]) + 1) / 2), int((int(temp[protected_attribute + 1]) + 1) / 2)])\n",
    "    \n",
    "    # as per the author's citation, we have transformed the input image\n",
    "    # (resize to 64×64, 256×256, 224×224)\n",
    "    pre_process = [(64, 64), (256, 256), (224, 224)]\n",
    "    mean_normalize = (0.485, 0.456, 0.406)\n",
    "    std_normalize = (0.229, 0.224, 0.225)\n",
    "    \n",
    "    if augment:\n",
    "        transform = A.Compose([\n",
    "            A.Resize(pre_process[0][0], pre_process[0][1]),\n",
    "            A.Resize(pre_process[1][0], pre_process[1][1]),\n",
    "            A.RandomCrop(width=pre_process[2][0], height=pre_process[2][1]),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.Normalize(mean=mean_normalize, std=std_normalize)\n",
    "        ])\n",
    "    \n",
    "    else:\n",
    "        transform = A.Compose([\n",
    "            A.Resize(pre_process[0][0], pre_process[0][1]),\n",
    "            A.Resize(pre_process[1][0], pre_process[1][1]),\n",
    "            A.CenterCrop(width=pre_process[2][0], height=pre_process[2][1]),\n",
    "            A.Normalize(mean=mean_normalize, std=std_normalize)\n",
    "        ])\n",
    "    if num_samples == -1:\n",
    "        num_samples = len(imgs)\n",
    "    else:\n",
    "        print(\"Num. of data ({}) is used for debugging\".format(num_samples))\n",
    "        \n",
    "    def load_func(i):\n",
    "        # crop the aligned & cropped 178×218 images to 128x128\n",
    "        cx = 121\n",
    "        cy = 89\n",
    "        c_pixels = 64\n",
    "        img = Image.open(imgs[i])\n",
    "        img = np.array(img.convert('RGB'))\n",
    "        img = img[cx - c_pixels:cx+c_pixels, cy-c_pixels:cy+c_pixels]\n",
    "        # transform\n",
    "        transformed_image = transform(image=img)['image'].transpose(2, 0, 1)\n",
    "        return transformed_image, labels[imgs[i]]\n",
    "    return data_iterator_simple(load_func, num_samples, batch_size, shuffle=shuffle, rng=rng, with_file_cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HltRTgTWHWnu"
   },
   "outputs": [],
   "source": [
    "def split_celeba_dataset(img_path, attr_path, out_dir, split=\"test\"):\n",
    "    \n",
    "    \"\"\"\n",
    "    split the celebA dataset\n",
    "    Args:\n",
    "        img_path (str) : image path directory \n",
    "        attr_path (str) : celebA attribute file path (ex: list_attr_celeba.txt)\n",
    "        out_dir (str) : Path where the split data to be saved\n",
    "        split (string) : split the dataset depends on the split attribute(train, valid, and test)\n",
    "    \"\"\"\n",
    "    # as per the author's citation, we are splitting the dataset\n",
    "    train_beg = 0  # train starts from\n",
    "    valid_beg = 162770  # valid starts from\n",
    "    test_beg = 182610  # test starts from\n",
    "    \n",
    "    label_file = open(attr_path, 'r')\n",
    "    label_file = label_file.readlines()\n",
    "    \n",
    "    # skipping the first two rows for header\n",
    "    total_samples = len(label_file) - 2\n",
    "    if split == 'train':\n",
    "        number_samples = valid_beg - train_beg\n",
    "        beg = train_beg\n",
    "    \n",
    "    elif split == 'valid':\n",
    "        number_samples = test_beg - valid_beg\n",
    "        beg = valid_beg\n",
    "    \n",
    "    elif split == 'test':\n",
    "        number_samples = total_samples - test_beg\n",
    "        beg = test_beg\n",
    "    else:\n",
    "        print('Error')\n",
    "        return\n",
    "    \n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "    \n",
    "    for i in range(beg + 2, beg + number_samples + 2):\n",
    "        temp = label_file[i].strip().split()\n",
    "        src_dir = os.path.join(img_path,temp[0])\n",
    "        dst_dir = os.path.join(out_dir,temp[0])\n",
    "        shutil.copy(src_dir, dst_dir)\n",
    "    print(\"splitting completed\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kSWa0yKxHWnw"
   },
   "source": [
    "### 2. Train Attribute Classifier\n",
    "\n",
    "Let's start with importing basic modules for GPU first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ih6Km9Q0HWnx"
   },
   "outputs": [],
   "source": [
    "from nnabla.ext_utils import get_extension_context\n",
    "ctx = get_extension_context('cudnn')\n",
    "nn.set_default_context(ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tbgOQzfLHWny"
   },
   "source": [
    "#### Now let's run Attribute Classifier \n",
    "\n",
    "For training Attribute Classifier, we have taken [ResNet-50](https://nnabla.org/pretrained-models/nnp_models/imagenet/Resnet-50/Resnet-50.nnp) pretrained on [ImageNet](https://image-net.org/) as the base architecture. We replaced the linear layer in ResNet with two linear layers with the hidden layer of size 2048. Dropout and ReLU are applied between these. We train all models with binary cross entropy loss for 20 epochs with a batch size of 32. We use the [Adam](https://arxiv.org/abs/1412.6980) optimizer with a learning rate of 1e-3.\n",
    "\n",
    "\n",
    "We have trained the Attribute Classifier and saved model with best accuracy on validation set. If you want to train the baseline Attribute Classifier from the scratch please refer to our GitHub page and follow the steps.\n",
    "\n",
    "\n",
    "Now let us get the pre-trained weights for the classifier and load the model. Then we shall check model fairness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rkd32-SaHWnz"
   },
   "outputs": [],
   "source": [
    "# download the celeba dataset and unzip\n",
    "URL = \"https://www.dropbox.com/s/d1kjpkqklf0uw77/celeba.zip?dl=0\"\n",
    "ZIP_FILE= \"./data/celeba.zip\"\n",
    "!mkdir -p ./data/\n",
    "!wget -N $URL -O $ZIP_FILE\n",
    "!unzip $ZIP_FILE -d ./data/\n",
    "!rm $ZIP_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the pre-trained weights\n",
    "!wget https://nnabla.org/pretrained-models/nnabla-examples/responsible_ai/gan_data_debiased/baseline.h5\n",
    "!wget https://nnabla.org/pretrained-models/nnabla-examples/responsible_ai/gan_data_debiased/val_baseline.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RD204iLsHWnz"
   },
   "outputs": [],
   "source": [
    "nn.clear_parameters()\n",
    "\n",
    "attribute_classifier_model = clf.attribute_classifier(model_load_path=r'baseline.h5')\n",
    "# split the dataset\n",
    "split_celeba_dataset(r'./data/celeba/images', r'./data/celeba/list_attr_celeba.txt', r'./test',split=\"test\")\n",
    "# load dataloader\n",
    "test = data_iterator_celeba(img_path= r'./test',\n",
    "                            attr_path= r'./data/celeba/list_attr_celeba.txt',\n",
    "                            batch_size=32, target_attribute=1, protected_attribute=20)\n",
    "cal_thresh = pickle.load(open(r'val_baseline.pkl', 'rb'))['cal_thresh']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nvVpE3JqHWn0"
   },
   "source": [
    "### Compute Attribute classifier fairness\n",
    "\n",
    "\n",
    "Let's start our investigation of classifier model fairness by analyzing the predictions made on test set. In this tutorial, we use average precission (AP) metric to measure classifier accuracy and three metrics to compute model fairness. First, we measure the [difference in equality of opportunity](https://arxiv.org/abs/2004.01355) (DEO), i.e. the absolute difference in False Negative Rate (FNR) for protected attribute group. As our second fairness metric, we use the [bias amplification](https://arxiv.org/abs/2102.12594) (BA) metric proposed by Wang and Russakovsky. Intuitively, BA measures how much more often a target attribute is predicted with a protected attribute than the ground truth value. Both DEO and BA fluctuate based on the chosen classification threshold. Therefore, as our final fairness metric, we use a threshold-invariant metric that measures the divergence between score distributions [(KL)](https://arxiv.org/abs/2006.10667).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EV_XMsJjHWn0"
   },
   "outputs": [],
   "source": [
    "test_targets, test_scores = attribute_classifier_model.get_scores(test)\n",
    "test_pred = np.where(test_scores > cal_thresh, 1, 0)\n",
    "\n",
    "ap = utils.get_average_precision(test_targets[:, 0], test_scores)\n",
    "deo = utils.get_difference_equality_opportunity(test_targets[:, 1],\n",
    "                                                     test_targets[:, 0], test_pred)\n",
    "ba = utils.get_bias_amplification(test_targets[:, 1],\n",
    "                                     test_targets[:, 0], test_pred)\n",
    "kl = utils.get_kl_divergence(test_targets[:, 1], test_targets[:, 0], test_scores)\n",
    "\n",
    "print('Test results: ')\n",
    "print('AP : {:.1f}', 100 * ap)\n",
    "print('DEO : {:.1f}', 100 * deo)\n",
    "print('BA : {:.1f}', 100 * ba)\n",
    "print('KL : {:.1f}', kl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gN0d3T0SHWn0"
   },
   "source": [
    "### 3. Mitigate the bias using GAN's Latent Space De-biasing\n",
    "\n",
    "As mentioned earlier in this notebook, to debias the dataset we need to generate a balanced synthetic dataset.\n",
    "\n",
    "\n",
    "To generate images, we use a Progressive GAN from nnabla-examples page. This is with 512-D latent space trained on the CelebA dataset. We use 10000 synthetic images, labeled with baseline attribute classifiers and learn hyperplanes (for both target and protected ht, hg) in the latent space with scikit-learn’s linear SVM implementation.\n",
    "\n",
    "\n",
    "In this tutorial, Progressive GAN training is skipped intentionally. Please refer to our [GitHub page](https://github.com/sony/nnabla-examples/tree/master/image-generation/pggan) for more info if you are interested in training PG GAN.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VfvCZnoHWn1"
   },
   "source": [
    "\n",
    "### 4. Train Attribute classifier with debiased dataset\n",
    "Well!\n",
    "Now we can train Attribute Classifier using both balanced synthetic dataset and original dataset. If you want to train the GAN-debiased model from the scratch please refer to our GitHub page and follow the steps.\n",
    "\n",
    "\n",
    "Let's get pre-trained weights of GAN-debiased model and check model fairness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the pre-trained weights\n",
    "!wget https://nnabla.org/pretrained-models/nnabla-examples/responsible_ai/gan_data_debiased/gan_data_debised.h5\n",
    "!wget https://nnabla.org/pretrained-models/nnabla-examples/responsible_ai/gan_data_debiased/val_gan_data_debised.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PFxaFeNoHWn1"
   },
   "outputs": [],
   "source": [
    "nn.clear_parameters()\n",
    "attribute_classifier_debiased_model = clf.attribute_classifier(model_load_path=r'gan_data_debised.h5')\n",
    "cal_thresh = pickle.load(open(r'val_gan_data_debised.pkl', 'rb'))['cal_thresh']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRrzwqK3HWn1"
   },
   "source": [
    "### Compute Fairness "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RED9xH5KHWn1"
   },
   "outputs": [],
   "source": [
    "test_targets, test_scores = attribute_classifier_debiased_model.get_scores(test)\n",
    "test_pred = np.where(test_scores > cal_thresh, 1, 0)\n",
    "\n",
    "ap = utils.get_average_precision(test_targets[:, 0], test_scores)\n",
    "deo = utils.get_difference_equality_opportunity(test_targets[:, 1],\n",
    "                                                     test_targets[:, 0], test_pred)\n",
    "ba = utils.get_bias_amplification(test_targets[:, 1],\n",
    "                                     test_targets[:, 0], test_pred)\n",
    "kl = utils.get_kl_divergence(test_targets[:, 1], test_targets[:, 0], test_scores)\n",
    "\n",
    "print('Test results: ')\n",
    "print('AP : {:.1f}', 100 * ap)\n",
    "print('DEO : {:.1f}', 100 * deo)\n",
    "print('BA : {:.1f}', 100 * ba)\n",
    "print('KL : {:.1f}', kl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQB2EqgzHWn2"
   },
   "source": [
    "If you observe above results with four metrics, GAN-debiased model performs better on all three fairness metrics: DEO, BA, and KL Divergence, while maintaining comparable AP over the baseline `Arched Brows` Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Ua9a635HWn2"
   },
   "source": [
    "### 5. Summary\n",
    "\n",
    "In this tutorial, we have shown how GAN-based data augmentation method could be employed to train a fairer Attribute Classifier in the presense of correlation between target label (Arched eyebrows) and a protected attribute (Gender Expression). In the same way, you may try different attribute classifiers. If there is bias in baseline Attribute Classifier model, try to balance the training data with an approach like GAN for data augmentation. To train different attribute classifiers, please refer to our GitHub page and follow the steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pdKkM-y-HWn2"
   },
   "source": [
    "### References\n",
    "1. Ramaswamy, Vikram V., Sunnie SY Kim, and Olga Russakovsky. \"Fair attribute classification through latent space de-biasing.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021\n",
    "2. Goodfellow, Ian, et al. \"Generative adversarial nets.\" Advances in neural information processing systems 27 (2014).\n",
    "3. Liu, Ziwei, et al. \"Large-scale celebfaces attributes (celeba) dataset.\" Retrieved August 15.2018 (2018): 11.\n",
    "4. Kingma, Diederik P., and Jimmy Ba. \"Adam: A method for stochastic optimization.\" arXiv preprint arXiv:1412.6980 (2014).\n",
    "5. Lokhande, Vishnu Suresh, et al. \"Fairalm: Augmented lagrangian method for training fair models with little regret.\" European Conference on Computer Vision. Springer, Cham, 2020.\n",
    "6. Wang, Angelina, and Olga Russakovsky. \"Directional bias amplification.\" International Conference on Machine Learning. PMLR, 2021.\n",
    "7. Chen, Mingliang, and Min Wu. \"Towards threshold invariant fair classification.\" Conference on Uncertainty in Artificial Intelligence. PMLR, 2020."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "gan_data_debiasing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
